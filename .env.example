# Server
PORT=3000
NODE_ENV=development

# Database
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/research_agent

# Redis (optional)
REDIS_URL=redis://localhost:6379

# ===========================================
# LLM Configuration
# ===========================================

# LLM Provider: groq | openai
LLM_PROVIDER=groq

# Groq (recommended - fast inference)
# Get API key at: https://console.groq.com/
GROQ_API_KEY=your_groq_api_key
GROQ_MODEL=qwen/qwen3-32b
GROQ_FAST_MODEL=llama-3.3-70b-versatile
GROQ_REASONING_MODEL=qwen/qwen3-32b

# OpenAI (alternative)
OPENAI_API_KEY=your_openai_api_key
OPENAI_MODEL=gpt-4o-mini

# ===========================================
# Paper Provider Configuration
# ===========================================

# Primary paper search provider: openalex | semantic_scholar | crossref
# OpenAlex is recommended as default (highest rate limits, good coverage)
PRIMARY_PAPER_PROVIDER=openalex

# OpenAlex polite pool - provide your email to get higher rate limits
# Without email: ~1 req/sec, With email: ~10 req/sec
# See: https://docs.openalex.org/how-to-use-the-api/rate-limits-and-authentication
OPENALEX_EMAIL=your_email@example.com

# Semantic Scholar API key (optional but recommended)
# Get one at: https://www.semanticscholar.org/product/api
# Without key: very limited rate (1 req/2sec), With key: ~10 req/sec
SEMANTICSCHOLAR_API_KEY=your_semantic_scholar_api_key

# Legacy alias for SEMANTICSCHOLAR_API_KEY (still supported)
# SEMANTIC_SCHOLAR_API_KEY=your_semantic_scholar_api_key

# ===========================================
# DeepResearch-Bench Evaluation
# ===========================================

# Jina Reader API for web scraping (required for FACT benchmark)
# Get API key at: https://jina.ai/reader/
JINA_API_KEY=your_jina_api_key

# Model for RACE evaluation (uses LLM_PROVIDER config above)
# RACE_EVAL_MODEL=gpt-4o
